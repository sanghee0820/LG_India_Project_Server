{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.engine import exporter\n",
    "\n",
    "# Î™®Îç∏ Î°úÎìú\n",
    "model = YOLO('best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.125 üöÄ Python-3.11.3 torch-2.0.1 CPU\n",
      "Model summary (fused): 168 layers, 3012083 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 37, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0-rc2...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.4s, saved as best.onnx (11.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i best.onnx -o best_saved_model -nuo --non_verbose'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 10.0s, saved as best_saved_model (29.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.13.0-rc2...\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success ‚úÖ 0.4s, saved as best.pb (11.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m starting export with tensorflowjs 3.18.0...\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m output node names: Identity:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file best_web_model/model.json...\n",
      "weight 1319 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1321 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_19/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1313 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1315 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_16/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1323 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1325 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_18/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1233 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1235 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_14/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1203 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1205 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_12/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1173 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1175 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_10/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1161 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1163 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_11/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1149 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1151 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_8/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1137 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1139 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_9/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1191 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1193 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_13/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1117 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1119 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_6/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1087 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1089 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_4/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1049 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1051 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_2/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1011 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1013 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 999 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1001 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_1/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1029 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1031 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_3/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1067 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1069 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_5/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1105 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1107 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_7/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1221 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1223 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_15/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1333 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1335 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_2/tf.strided_slice_17/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m export success ‚úÖ 2.9s, saved as best_web_model (11.8 MB)\n",
      "\n",
      "Export complete (13.5s)\n",
      "Results saved to \u001b[1m/Users/sanghee/Desktop/LG_Internship/YOLO\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best_web_model imgsz=640 \n",
      "Validate:        yolo val task=detect model=best_web_model imgsz=640 data=/content/Data/data.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "result = model.export(format = \"tfjs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
