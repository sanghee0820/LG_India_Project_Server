{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.engine import exporter\n",
    "\n",
    "# Î™®Îç∏ Î°úÎìú\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.125 üöÄ Python-3.11.3 torch-2.0.1 CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.0-rc2...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.33...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.5s, saved as yolov8n.onnx (12.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m running 'onnx2tf -i yolov8n.onnx -o yolov8n_saved_model -nuo --non_verbose'\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 10.0s, saved as yolov8n_saved_model (30.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.13.0-rc2...\n",
      "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success ‚úÖ 0.3s, saved as yolov8n.pb (12.3 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m starting export with tensorflowjs 3.18.0...\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m output node names: Identity:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file yolov8n_web_model/model.json...\n",
      "weight 1331 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1333 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_19/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1325 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1327 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_16/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1335 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1337 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_18/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1245 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1247 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_14/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1215 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1217 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_12/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1185 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1187 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_10/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1173 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1175 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_11/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1161 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1163 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_8/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1149 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1151 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_9/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1203 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1205 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_13/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1129 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1131 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_6/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1099 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1101 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_4/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1061 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1063 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_2/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1023 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1025 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1011 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1013 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_1/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1041 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1043 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_3/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1079 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1081 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_5/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1117 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1119 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_7/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1233 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1235 with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_15/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n",
      "weight 1345 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight 1347 with shape (3,) and dtype int64 was auto converted to the type int32\n",
      "weight PartitionedCall/model_8/tf.strided_slice_17/StridedSlice/strides with shape (3,) and dtype int64 was auto converted to the type int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m export success ‚úÖ 2.7s, saved as yolov8n_web_model (12.3 MB)\n",
      "\n",
      "Export complete (13.3s)\n",
      "Results saved to \u001b[1m/Users/sanghee/Desktop/LG_Internship/YOLO\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n_web_model imgsz=640 \n",
      "Validate:        yolo val task=detect model=yolov8n_web_model imgsz=640 data=coco.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "result = model.export(format = \"tfjs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ultralytics.yolo.engine.model.YOLO object at 0x281baf090>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
